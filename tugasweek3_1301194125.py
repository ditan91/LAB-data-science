# -*- coding: utf-8 -*-
"""TugasWeek3_1301194125.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17yc7jAZVepUo6taCG2-fifz23jZGHRLu
"""

import pandas as pd
import numpy as np
import seaborn as sns
import sklearn
import matplotlib.pyplot as plt

print(f"Pandas Ver : {pd.__version__}")
print(f"Numpy  Ver : {np.__version__}")
print(f"Sklearn Ver : {sklearn.__version__}")
print(f"Seaborn Ver : {sns.__version__}")

data = pd.read_csv('dataset.csv')
data

data.info()

plt.plot(data["LotArea"],data["SalePrice"],"o")
plt.title("Lot Area")
plt.xlabel("Sale Price")
plt.show()

"""scatter plot diatas adalah antara (scaling) dari Lot Area dengan sale price dari rumah. jika dilihat dari scatter plot tersebut maka terdapat outlier (pencilan) yang cukup jauh dari yang lain, yaitu pada saleprice dengan scalling lebih dari 25, tentu hal ini harus diteliti lebih lanjut untuk menemukan situasi yang tidak normal"""

plt.plot(data["YearRemodAdd"],data["SalePrice"],"o")
plt.title("Year Remodelling Addition")
plt.xlabel("Sale Price")
plt.show()

"""untuk scatter plot diatas antara year remodel dengan saleprice merupakan jenis non-liniear karna membentuk curva"""

plt.plot(data["ExterQual"],data["SalePrice"],"o")
plt.title("ExterQuality")
plt.xlabel("Sale Price")
plt.show()

"""scatter plot antara exterrior quality memiliki hubungan yang positif, hal ini dikarenakan ketika nilai exterior quality semakin tinggi maka sale price juga semakin tinggi"""

plt.plot(data["Street"],data["SalePrice"],"o")
plt.title("Street")
plt.xlabel("Sale Price")
plt.show()

"""scatter plot antara street dengan saleprice tidak memiliki hubungan (sedikit) korelasi , hal ini dikarenakan nilai x bisa naik atau turun tergantung nilai y"""

plt.plot(data["OverallQual"],data["SalePrice"],"o")
plt.title("Overall Quality")
plt.xlabel("Sale Price")
plt.show()

"""scatter plot antara overall quality dengan saleprice memiliki bentuk scatter plot yang positif sama seperti exterior quality dengan saleprice, karna semakin tinggi sale price dibarengi dengan nilai overall quality yang tinggi juga"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error as mse
StandardScalerObj = StandardScaler()
X = StandardScalerObj.fit_transform(data.iloc[:,:-1])
Y = np.log(data["SalePrice"])
train,test,ytrain,ytest = train_test_split(X,Y)

data.iloc[:,:-1] = X
data["SalePrice"] = Y

LinearRegressionObj = LinearRegression()
LinearRegressionObj.fit(train,ytrain)
ypred = LinearRegressionObj.predict(test)
mse(LinearRegressionObj.predict(test),ytest)

plt.figure(figsize=(10,8))
sns.regplot(x=np.arange(len(ytest)),y=ytest)
print(f"mean : {ytest.mean()}")
print(f"std : {ytest.std()}")
print(f"max : {ytest.max()}")
print(f"min : {ytest.min()}")

"""terlihat jika sebaran datanya tersebar secara acak diatas dan dibawah garis horizontal (kurang lebih) diantara 2,48-2,50, sehingga membuktikan jika x dan y tidak saling berhubungan"""

plt.figure(figsize=(10,8))
sns.regplot(x=np.arange(len(ypred)),y=ypred)
print(f"mean :{ypred.mean()}")
print(f"std : {ypred.std()}")
print(f"max : {ypred.max()}")
print(f"min : {ypred.min()}")

"""terlihat jika sebaran datanya tersebar secara acak diatas dan dibawah garis horizontal (kurang lebih) diantara 2,48-2,50, sehingga membuktikan jika tidak ada hubungan linier antara x dan y"""

from sklearn.metrics import mean_squared_error,mean_absolute_error
print(f"MSE : {mean_squared_error(ytest,ypred)}")
print(f"MAE : {mean_absolute_error(ytest,ypred)}")
print(f"RMSE : {np.sqrt(mean_squared_error(ytest,ypred))}")

"""*   MAE : sama seperti MSE namun MAE lebih absoulut dalam perhitungannya atau bisa dibilang lebih 
*   MSE : rata-rata dari kesalah selisih atau kuadrat antara nilai prediksi dengan nilai asli, MSE lebih sensitif terhadap outlier dan dapat menunjukan seberapa variasinya suatu model
*   RMSE : merupakan jumlah dari kesalahan selisih atau kuadrat antara nilai sebenarnya dengan nilai prediksi

dilihat dari hasil MSE, MAE, dan RMSE pada dataset.csv nilai MSE lebih kecil dari pada MAE sehingga variasi data dalam dataset.csv tidak terlalu besar (tidak banyak nilai pencilan dalam data tersebut), karna nilai MSE akan bernilai besar ketika ditemukan banyak nilai pencilan, pada MSE nilai pencilan diberikan bobot yang besar dan akan mempengaruhi hasil perhitungan dari MSE. namun pada data set ini MSE memiliki nilai yang lebih kecil sehingga bisa disimpulkan jika dalam dataset tidak banyak ditemukan pencilan.

untuk nilai MAE, ditemukan hasil 0,0106 hal ini menyatakan jika rata-rata kesalahan absolut dari nilai sebenarnya dengan nilai prediksi ialah 0,0106

untuk nilai RMSE nilainya hampir mendekati 0, hal ini dapat diartikan sebagai nilai yang diprediksi dekat dengan nilai yang sebenarnya
"""

LinearRegressionObj.coef_

"""Regresi adalah proses memprediksi nilai kontinu sebagai lawan dari prediksi nilai kategorikal dalam Klasifikasi (sumber slide pengatar AI Telkom University), sehingga jika diliat dari sebaran data yang dimiliki maka regresi data ini jenisnya adalah regresi non linear karna sebaran datanya menyebar"""



display(f"Model Formula : {LinearRegressionObj.intercept_} + {tuple(data.columns[val]+'*'+ str(LinearRegressionObj.coef_[val]) for val in range(len(LinearRegressionObj.coef_)))}".replace(","," +"))

#menentukan overfit, underfit, besfit

from sklearn.neural_network import MLPRegressor 
from sklearn.metrics import mean_absolute_error
import numpy as np
from sklearn.model_selection import validation_curve
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
np.random.seed(0)
plt.style.use('ggplot')

iris = load_iris()
X, y = iris.data, iris.target

kf = KFold(n_splits=20)
list_training_error = []
list_testing_error = []
for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model = MLPRegressor()
    model.fit(X_train, y_train)
    y_train_data_pred = model.predict(X_train)
    y_test_data_pred = model.predict(X_test)    
    
    fold_training_error = mean_absolute_error(y_train, y_train_data_pred) 
    fold_testing_error = mean_absolute_error(y_test, y_test_data_pred)
    list_training_error.append(fold_training_error)
    list_testing_error.append(fold_testing_error)

plt.subplot(1,2,1)
plt.plot(range(1, kf.get_n_splits() + 1), np.array(list_training_error).ravel(), 'o-')
plt.xlabel('number of fold')
plt.ylabel('training error')
plt.title('Training error across folds')
plt.tight_layout()
plt.subplot(1,2,2)
plt.plot(range(1, kf.get_n_splits() + 1), np.array(list_testing_error).ravel(), 'o-')
plt.xlabel('number of fold')
plt.ylabel('testing error')
plt.title('Testing error across folds')
plt.tight_layout()
plt.show()

"""pada titik fold 5 diidentifikasi jika kesalahan pada training dan testing sangat tinggi, sehingga pada titik tersebut merupakan titik underfit

dan ketika pada titik fold 10 merupakan titik overfit, karena pada training di titik fold 10 sangat rendah namu pada testing ketika di titik 10 nilainya lebih besar dr pada di training.


sumber : https://towardsdatascience.com/is-your-model-overfitting-or-maybe-underfitting-an-example-using-a-neural-network-in-python-4faf155398d2
"""